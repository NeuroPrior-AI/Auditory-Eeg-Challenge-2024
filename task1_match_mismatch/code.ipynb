{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, random_split\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "# from torchsummary import summary\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "directory = 'E:/split_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Block for the CNN part of the network, using 1D convolutions\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # First 1D convolutional layer\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        # Second 1D convolutional layer\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "# CRNN Model for EEG Encoding, with 1D convolutions\n",
    "class CRNNEncoder(nn.Module):\n",
    "    def __init__(self, rnn_type='LSTM', in_channel=64):\n",
    "        super(CRNNEncoder, self).__init__()\n",
    "        self.current_channels = in_channel  # Current number of channels\n",
    "\n",
    "        # 1D CNN layers with residual connections\n",
    "        self.layer1 = self._make_layer(BasicBlock, 128, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 256, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 512, 2, stride=2)\n",
    "        # self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2)\n",
    "\n",
    "        # RNN layer\n",
    "        self.hidden_size = 128\n",
    "        if rnn_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(512, self.hidden_size, batch_first=True)\n",
    "        elif rnn_type == 'GRU':\n",
    "            self.rnn = nn.GRU(512, self.hidden_size, batch_first=True)\n",
    "        else: # RNN\n",
    "            self.rnn = nn.RNN(512, self.hidden_size, batch_first=True)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.current_channels, out_channels, stride))\n",
    "            self.current_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through 1D CNN layers\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        # out = self.layer4(out)\n",
    "\n",
    "        # Flatten and pass through RNN\n",
    "        out = out.view(out.size(0), -1, 512)\n",
    "        out, _ = self.rnn(out)\n",
    "\n",
    "        # Option 1: Return the output of the last CNN layer for encoding\n",
    "        # cnn_encoding = out.view(out.size(0), -1)\n",
    "        # return cnn_encoding\n",
    "\n",
    "        # Option 2: Return the output of the RNN layer for encoding\n",
    "        rnn_encoding = out[:, -1, :]  # Using the last time step\n",
    "        return rnn_encoding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, embedding_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Define the contrastive loss with cosine similarity\n",
    "class ContrastiveCosineLoss(nn.Module):\n",
    "    def __init__(self, margin=0.5):\n",
    "        super(ContrastiveCosineLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.cosine_similarity = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # Cosine similarity\n",
    "        cos_sim = self.cosine_similarity(output1, output2)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = (1 - label) * 0.5 * cos_sim**2 + \\\n",
    "               label * 0.5 * (torch.relu(self.margin - cos_sim) ** 2)\n",
    "        \n",
    "        return loss.mean()\n",
    "    \n",
    "    \n",
    "class EEGMelDataset(Dataset):\n",
    "    def __init__(self, eeg_data, mel_data):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with EEG and Mel spectrogram data.\n",
    "        :param eeg_data: Numpy array of EEG data with shape [10000, 320, 65]\n",
    "        :param mel_data: Numpy array of Mel spectrogram data with shape [10000, 320, 10]\n",
    "        \"\"\"\n",
    "        assert eeg_data.shape[0] == mel_data.shape[0], \"EEG and Mel data must have the same number of samples\"\n",
    "        \n",
    "        self.eeg_data = torch.from_numpy(eeg_data)\n",
    "        self.mel_data = torch.from_numpy(mel_data)\n",
    "        \n",
    "        self.non_matching_indices = [random.choice([i for i in range(len(self)) if i != idx]) for idx in range(len(self))]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return self.eeg_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a pair of EEG and Mel spectrogram samples along with a label indicating correspondence.\n",
    "        \"\"\"\n",
    "        # Randomly decide whether to fetch a corresponding pair or not\n",
    "        match = np.random.randint(0, 2)  # 0 or 1\n",
    "        eeg_sample = self.eeg_data[idx]\n",
    "\n",
    "        if match:\n",
    "            mel_sample = self.mel_data[idx]\n",
    "        else:\n",
    "            non_matching_idx = self.non_matching_indices[idx]\n",
    "            mel_sample = self.mel_data[non_matching_idx]\n",
    "\n",
    "        return eeg_sample, mel_sample, torch.tensor(match, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(cos_sim, labels, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy based on cosine similarity and labels.\n",
    "    Args:\n",
    "    - cos_sim (Tensor): Cosine similarity between pairs.\n",
    "    - labels (Tensor): Actual labels indicating if pairs are matching.\n",
    "    - threshold (float): Threshold for deciding if pairs are considered a match.\n",
    "    Returns:\n",
    "    - accuracy (float): The accuracy of predictions.\n",
    "    \"\"\"\n",
    "    preds = cos_sim > threshold\n",
    "    correct = torch.sum(preds == labels.bool()).item()\n",
    "    total = labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "def train(eeg_encoder, mel_eocoder, criterion, optimizer, train_set, test_set, batch_size, num_epochs=10, lr_decay_patience=5, early_stopping_patience=10):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    \n",
    "    # stop_training = False\n",
    "\n",
    "    # def check_for_input():\n",
    "    #     global stop_training\n",
    "    #     input(\"Press Enter to stop training after the current epoch...\\n\")\n",
    "    #     stop_training = True\n",
    "    \n",
    "    # input_thread = threading.Thread(target=check_for_input)\n",
    "    # input_thread.daemon = True  # This ensures the thread will be killed when the main program exits\n",
    "    # input_thread.start()\n",
    "\n",
    "    eeg_encoder = eeg_encoder.to(device)\n",
    "    mel_eocoder = mel_eocoder.to(device)\n",
    "\n",
    "    # Scheduler for learning rate decay\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=lr_decay_patience, factor=0.5)\n",
    "    prev_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    best_test_loss = float('inf')\n",
    "    best_test_accu = float('-inf')\n",
    "    \n",
    "    epochs_no_improve = 0\n",
    "    early_stop = False\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accus = []\n",
    "    test_accus = []\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        # if stop_training:\n",
    "        #     print(\"Stopping training...\")\n",
    "        #     break\n",
    "    \n",
    "        # ========== Training Loop ==========\n",
    "        eeg_encoder.train()\n",
    "        mel_eocoder.train()\n",
    "        \n",
    "        train_loss = 0\n",
    "        train_accu = 0\n",
    "        for eeg, mel, labels in train_loader:\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast():\n",
    "                eeg_embedding = eeg_encoder(eeg.to(device))\n",
    "                mel_embedding = mel_eocoder(mel.to(device))\n",
    "                \n",
    "                cos_sim = nn.CosineSimilarity(dim=1, eps=1e-6)(eeg_embedding, mel_embedding)\n",
    "                train_accu += calculate_accuracy(cos_sim, labels.to(device))\n",
    "                \n",
    "                loss = criterion(eeg_embedding, mel_embedding, labels.to(device))\n",
    "            \n",
    "            # Scales loss, calls backward() to create scaled gradients\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # Optimizer step and update scaler\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        train_accus.append(train_accu / len(train_loader))\n",
    "\n",
    "        # ========== Testing Loop ==========\n",
    "        eeg_encoder.eval()\n",
    "        mel_eocoder.eval()\n",
    "        test_loss = 0\n",
    "        test_accu = 0\n",
    "        with torch.no_grad():\n",
    "            for eeg, mel, labels in test_loader:\n",
    "                \n",
    "                eeg_embedding = eeg_encoder(eeg.to(device))\n",
    "                mel_embedding = mel_eocoder(mel.to(device))\n",
    "                \n",
    "                cos_sim = nn.CosineSimilarity(dim=1, eps=1e-6)(eeg_embedding, mel_embedding)\n",
    "                test_accu += calculate_accuracy(cos_sim, labels.to(device))\n",
    "                \n",
    "                loss = criterion(eeg_embedding, mel_embedding, labels.to(device))\n",
    "                test_loss += loss.item()\n",
    "\n",
    "            test_losses.append(test_loss / len(test_loader))\n",
    "            test_accus.append(test_accu / len(test_loader))\n",
    "    \n",
    "        # ========== Update scheduler ==========\n",
    "        scheduler.step(test_losses[-1])\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        if current_lr != prev_lr:\n",
    "            print(f\"Epoch {epoch}: Learning rate changed to {current_lr}\")\n",
    "            prev_lr = current_lr\n",
    "            \n",
    "        # Save model parameters\n",
    "        curr_accu = test_accus[-1]\n",
    "        if curr_accu > best_test_accu:\n",
    "            best_test_accu = curr_accu\n",
    "            torch.save(eeg_encoder.state_dict(), f'eeg_encoder_best.pth')\n",
    "            torch.save(mel_eocoder.state_dict(), f'mel_encoder_best.pth')\n",
    "            print(f\"Epoch {epoch+1}: Test accuracy improved to {curr_accu:.4f}, saving model.\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if test_losses[-1] < best_test_loss:\n",
    "            best_test_loss = test_losses[-1]\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= early_stopping_patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                early_stop = True\n",
    "\n",
    "        if early_stop:\n",
    "            break\n",
    "\n",
    "        print(f\"Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}, Train Accu: {train_accus[-1]:.4f}, Test Accu: {test_accus[-1]:.4f}\")\n",
    "        print('===============')\n",
    "\n",
    "    return train_losses, train_accus, test_losses, test_accus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eeg = np.transpose(np.load('train_x.npy'), (0, 2, 1))\n",
    "train_mel = np.transpose(np.load('train_y.npy'), (0, 2, 1))\n",
    "test_eeg = np.transpose(np.load('test_x.npy'), (0, 2, 1))\n",
    "test_mel = np.transpose(np.load('test_y.npy'), (0, 2, 1))\n",
    "\n",
    "train_set = EEGMelDataset(train_eeg, train_mel)\n",
    "test_set = EEGMelDataset(test_eeg, test_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:03<19:05,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Test accuracy improved to 0.5109, saving model.\n",
      "Train Loss: 0.0471, Test Loss: 0.0431, Train Accu: 0.5005, Test Accu: 0.5109\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/300 [00:06<14:42,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0384, Test Loss: 0.0421, Train Accu: 0.4938, Test Accu: 0.5109\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/300 [00:08<13:11,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0348, Test Loss: 0.0333, Train Accu: 0.5047, Test Accu: 0.4746\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/300 [00:10<12:31,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0341, Test Loss: 0.0333, Train Accu: 0.4977, Test Accu: 0.4717\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/300 [00:13<12:08,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0339, Test Loss: 0.0328, Train Accu: 0.4974, Test Accu: 0.4891\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/300 [00:15<11:49,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0337, Test Loss: 0.0328, Train Accu: 0.5017, Test Accu: 0.5022\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/300 [00:17<11:40,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Test accuracy improved to 0.5269, saving model.\n",
      "Train Loss: 0.0338, Test Loss: 0.0337, Train Accu: 0.5089, Test Accu: 0.5269\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/300 [00:20<11:32,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0337, Test Loss: 0.0331, Train Accu: 0.5054, Test Accu: 0.5080\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/300 [00:22<11:29,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0339, Test Loss: 0.0339, Train Accu: 0.4978, Test Accu: 0.4615\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/300 [00:24<11:15,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0336, Test Loss: 0.0336, Train Accu: 0.4857, Test Accu: 0.4964\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 11/300 [00:27<11:08,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0335, Test Loss: 0.0340, Train Accu: 0.4935, Test Accu: 0.4790\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/300 [00:29<11:03,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0331, Test Loss: 0.0338, Train Accu: 0.5055, Test Accu: 0.5109\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 13/300 [00:31<11:02,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0330, Test Loss: 0.0333, Train Accu: 0.4997, Test Accu: 0.5094\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 14/300 [00:33<11:01,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0329, Test Loss: 0.0331, Train Accu: 0.4992, Test Accu: 0.5080\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 15/300 [00:36<10:59,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0328, Test Loss: 0.0326, Train Accu: 0.4949, Test Accu: 0.4993\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 16/300 [00:38<10:57,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0324, Test Loss: 0.0325, Train Accu: 0.4977, Test Accu: 0.4499\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 17/300 [00:41<11:01,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Test accuracy improved to 0.5356, saving model.\n",
      "Train Loss: 0.0324, Test Loss: 0.0325, Train Accu: 0.4929, Test Accu: 0.5356\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 18/300 [00:43<11:01,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0324, Test Loss: 0.0326, Train Accu: 0.4964, Test Accu: 0.5080\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 19/300 [00:45<10:55,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0323, Test Loss: 0.0314, Train Accu: 0.4963, Test Accu: 0.4862\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/300 [00:47<10:50,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0323, Test Loss: 0.0324, Train Accu: 0.5045, Test Accu: 0.5109\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 21/300 [00:50<10:47,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0322, Test Loss: 0.0329, Train Accu: 0.5115, Test Accu: 0.5094\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 22/300 [00:52<10:46,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0322, Test Loss: 0.0325, Train Accu: 0.5084, Test Accu: 0.4877\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 23/300 [00:54<10:47,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0320, Test Loss: 0.0322, Train Accu: 0.5014, Test Accu: 0.4833\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 24/300 [00:57<10:45,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0320, Test Loss: 0.0328, Train Accu: 0.5004, Test Accu: 0.4659\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 25/300 [00:59<10:39,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0318, Test Loss: 0.0325, Train Accu: 0.5007, Test Accu: 0.4978\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 26/300 [01:01<10:40,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0316, Test Loss: 0.0324, Train Accu: 0.5019, Test Accu: 0.4935\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 27/300 [01:04<10:38,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0317, Test Loss: 0.0328, Train Accu: 0.4944, Test Accu: 0.5239\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 28/300 [01:06<10:36,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0312, Test Loss: 0.0321, Train Accu: 0.5037, Test Accu: 0.5094\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 29/300 [01:09<10:35,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0311, Test Loss: 0.0316, Train Accu: 0.5145, Test Accu: 0.5036\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 30/300 [01:11<10:33,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Learning rate changed to 0.005\n",
      "Train Loss: 0.0303, Test Loss: 0.0318, Train Accu: 0.5048, Test Accu: 0.4848\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 31/300 [01:13<10:19,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0297, Test Loss: 0.0313, Train Accu: 0.4927, Test Accu: 0.5152\n",
      "===============\n"
     ]
    }
   ],
   "source": [
    "eeg_encoder = CRNNEncoder(rnn_type='LSTM', in_channel=65).cuda()\n",
    "audio_encoder = CRNNEncoder(rnn_type='LSTM', in_channel=10).cuda()\n",
    "\n",
    "criterion = ContrastiveCosineLoss()\n",
    "optimizer = optim.Adam(eeg_encoder.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 300\n",
    "batch_size = 900\n",
    "lr_decay = 10\n",
    "early_stopping = 20\n",
    "train_loss, train_accu, test_loss, test_accu = train(eeg_encoder, \n",
    "                                                     audio_encoder, \n",
    "                                                     criterion, \n",
    "                                                     optimizer, \n",
    "                                                     train_set, \n",
    "                                                     test_set, \n",
    "                                                     batch_size, \n",
    "                                                     epochs, \n",
    "                                                     lr_decay, \n",
    "                                                     early_stopping)\n",
    "\n",
    "trained_epochs = len(train_loss)\n",
    "x_range = np.linspace(1, trained_epochs, trained_epochs)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(x_range, train_loss, label='Training loss')\n",
    "plt.plot(x_range, test_loss, label='Test loss')\n",
    "plt.title('loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(x_range, train_accu, label='Training Accu')\n",
    "plt.plot(x_range, test_accu, label='Test Accu')\n",
    "plt.title('Accu')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accu')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
